{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T21:20:24.300748Z",
     "start_time": "2023-07-06T21:20:24.285749Z"
    },
    "code_folding": [
     9,
     40,
     79
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "# reading FASTQs from illumina\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def find_nth_n_str(string, leter, n):\n",
    "    \n",
    "    \"\"\" finds index of the nth letter in a string \n",
    "    \n",
    "    find_nth_n_str(string, leter,n)\n",
    "        string: str to search \n",
    "        leter: str charater to find \n",
    "        n: int how many letters to skip-1\n",
    "        \n",
    "    \"\"\"\n",
    "    ################### check inputs #########################\n",
    "    if type(string) != str:\n",
    "        raise TypeError('string must be of type str not '+ str(type(string)))\n",
    "    if type(leter) != str:\n",
    "        raise TypeError('leter must be of type str not '+ str(type(leter)))\n",
    "    if type(n) != int:\n",
    "        raise TypeError('n must be of type str not '+ str(type(n)))\n",
    "    ##########################################################\n",
    "        \n",
    "    m=0\n",
    "    for c, char in enumerate(string):\n",
    "        if m<n:\n",
    "            if char == leter:\n",
    "                m+=1\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            return(c-1)\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def read_illlumina_FASTQ(FASTQ_path):\n",
    "    \n",
    "    \"\"\" read illumina fastq and return line ID, sequence, and Q score\n",
    "    \n",
    "    read_illlumina_FASTQ(FASTQ_path)\n",
    "        FASTQ_path: fastq path\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    fastq_file = open(os.path.normpath(FASTQ_path), 'r')\n",
    "    ID_SEQ_Q = {}\n",
    "    line_count = 0\n",
    "\n",
    "    while True:\n",
    "        line = fastq_file.readline()\n",
    "        line_count += 1\n",
    "        if line == '':\n",
    "            continue\n",
    "        if line == 'end':\n",
    "            break\n",
    "        if line[0:2] == '@M':\n",
    "            ID_line =  line\n",
    "            seq_line = fastq_file.readline().replace('\\n','')\n",
    "            line_count += 1\n",
    "            Plus_line = fastq_file.readline().replace('\\n','')\n",
    "            line_count += 1\n",
    "            quality_line = fastq_file.readline().replace('\\n','')\n",
    "            line_count += 1\n",
    "            Q = np.mean([ord(q)-33 for q in quality_line])\n",
    "            #@M00179:299:000000000-KDNHP:1:1101:9576:1149 1:N:0:NNNNNNNN+NNNNNNCN\n",
    "            #@<instrument>:<run number>:<flowcell ID>:<lane>:<tile>:<x-pos>:<y-pos>:<UMI> <read>:<is filtered>:<control number>:<index>\n",
    "            ID = ID_line[:find_nth_n_str(ID_line,' ',1)]\n",
    "            ID_SEQ_Q[ID] = (seq_line,Q)\n",
    "    fastq_file.close()\n",
    "    print(str(line_count/4))\n",
    "    return(ID_SEQ_Q)\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def comR1_R2(FASTQ_R1,FASTQ_R2):\n",
    "    \n",
    "    \"\"\" read illumina fastqs and create combind datafram for read 1 and 2\n",
    "    \n",
    "    comR1_R2(FASTQ_R1,FASTQ_R2)\n",
    "        FASTQ_R1: fastq read 1 path \n",
    "        FASTQ_R2: fastq read 2 path \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    Read1 = read_illlumina_FASTQ(FASTQ_R1)\n",
    "    print('fastQ 1 red')\n",
    "    Read2 = read_illlumina_FASTQ(FASTQ_R2)\n",
    "    print('fastQ 2 red')\n",
    "    \n",
    "    R1 = []\n",
    "    R2 = []\n",
    "    Q1 = []\n",
    "    Q2 = []\n",
    "    readnum = 0\n",
    "    for Id in Read1:\n",
    "        if Read2.get(Id) == None:\n",
    "            continue\n",
    "        else:\n",
    "            r2, q2 = Read2[Id]\n",
    "            r1, q1 = Read1[Id]\n",
    "            R1.append(r1)\n",
    "            R2.append(r2)\n",
    "            Q1.append(q1)\n",
    "            Q2.append(q2)\n",
    "            readnum += 1\n",
    "    df = pd.DataFrame(data = {'R1':R1,'R2':R2,'Q1':Q1,'Q2':Q2}, columns = ['R1','R2','Q1','Q2'])  \n",
    "    return(df)\n",
    "\n",
    "# =============================================================================\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     31,
     49,
     68,
     90
    ]
   },
   "outputs": [],
   "source": [
    "# look up tables (dict) for analysis\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def DNA2int(DNA, N = 'A'):\n",
    "    ''' Converts DNA into intiger form.\n",
    "    \n",
    "        DNA: str DNA with bases A,T,G,C,a,t,g,c \n",
    "        N: 'random', None, or bases A,T,G,C,a,t,g,c \n",
    "        returns an intager repersentation of DNA, if DNA has base not in above \n",
    "        list, return 0\n",
    "        \n",
    "    '''    \n",
    "    d2b = {'A':'00','C':'01','T':'10','G':'11','a':'00','c':'01','t':'10','g':'11'}\n",
    "    bs = '1'\n",
    "    # binary 000000 -> 0 not AAAA so all codes have to start with a 1 so no ambugiuity\n",
    "    for base in DNA:\n",
    "        if d2b.get(base) == None:\n",
    "            if N != None and base in 'Nn':\n",
    "                if N == 'random':\n",
    "                    base = random.choice(['A','T','C','G'])\n",
    "                elif type(N) == str:\n",
    "                    base = N\n",
    "            else:\n",
    "                raise Exception('base <'+base+'> not in libuary (A,T,G,C,a,t,g,c)') \n",
    "        bs+=d2b[base]\n",
    "    intager = int(bs, 2)\n",
    "    return(intager)\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def int2DNA(intager):\n",
    "    ''' Converts intager into DNA form.\n",
    "    \n",
    "        DNA: int DNA \n",
    "        returns an DNA str with bases A,T,G,C or None if intager is 0\n",
    "        \n",
    "    '''\n",
    "    b2d = {'00':'A','01':'C','10':'T','11':'G'}\n",
    "    # 3 because the bin finction gives '0b1(the code for seq)' the leading 1 is because leading 0 are ambiguous \n",
    "    bi = bin(intager)[3:]\n",
    "    seq = ''\n",
    "    for sec in range(int(len(bi)/2)):\n",
    "        loc = sec*2\n",
    "        seq += b2d[bi[loc:loc+2]]\n",
    "    return(seq)\n",
    "    \n",
    "# =============================================================================\n",
    "\n",
    "def hamming_close_1(seq):\n",
    "    \n",
    "    ''' return DNA sequences list that are hamming distance 1 away \n",
    "    \n",
    "        seq: str DNA sequence with bases A,T,G,C\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    close = []\n",
    "    seq = list(seq)\n",
    "    alph = ['A','C','T','G']\n",
    "    for base in range(len(seq)):\n",
    "        for N in alph:\n",
    "            N_seq = seq[0:base] +[N] + seq[base+1:]\n",
    "            close.append(\"\".join(N_seq))\n",
    "    return(close)\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def hamming_close(seq, distance = 1):\n",
    "    ''' return DNA sequences list that are hamming distance away definded by distance\n",
    "    \n",
    "        seq: str DNA sequence with bases A,T,G,C\n",
    "        distance: int, max hamming distance of sequences returned\n",
    "        \n",
    "    '''\n",
    "    h0 = [seq]\n",
    "    hammings_done = 0\n",
    "    while True:\n",
    "        if hammings_done == distance:\n",
    "            break\n",
    "        else:\n",
    "            hp = []\n",
    "            for w in h0:\n",
    "                hp += hamming_close_1(w)\n",
    "            h0 = hp\n",
    "            hammings_done += 1\n",
    "    return(h0)\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def hamming_close_FP(seq,FP):\n",
    "    ''' return DNA sequences list that are hamming distance 2 away and list of name FP that is \n",
    "        same length as returned list of sequences\n",
    "    \n",
    "        seq: str DNA sequence with bases A,T,G,C\n",
    "        FP: str, name of sequense to be retuned in list\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    HC_seqs = [DNA2int(DNA, N = 'A') for DNA in hamming_close(seq,distance = 2)]\n",
    "    FPs = [FP]*len(HC_seqs)\n",
    "    return(HC_seqs,FPs)\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "# probe lookup table \n",
    "\n",
    "Gene_probe_path = 'Path/to/CSV' #formated CSV with columns named: gene_sym, targeting_seqs\n",
    "# with the targeting seq formated like \"ACTGACTG, ACTGACTG\". -> left probe, right probe\n",
    "\n",
    "Gene_probe = pd.read_csv(Gene_probe_path)\n",
    "\n",
    "# number probes if not numbered to make unique names\n",
    "Gene_probe_path_lib = {}\n",
    "name_dict = {}\n",
    "for FP,seq in zip(Gene_probe['gene_sym'].tolist(),\n",
    "                  Gene_probe['targeting_seqs'].tolist()):\n",
    "    \n",
    "    num=1\n",
    "    while name_dict.get(FP+'_'+str(num)) != None:\n",
    "        num+=1\n",
    "    \n",
    "    num_name = FP+'_'+str(num)\n",
    "    name_dict[FP+'_'+str(num)]=num\n",
    "    \n",
    "    Gene_probe_path_lib[seq[-30:]] = [num_name,FP,'R']\n",
    "    Gene_probe_path_lib[seq[:30]] = [num_name,FP,'L']\n",
    "\n",
    "# generate probe lookup table\n",
    "probe_Look_up = {} \n",
    "\n",
    "SEQ = []\n",
    "FP_num = []\n",
    "for seq in Gene_probe_path_lib:\n",
    "    FP_num.append(Gene_probe_path_lib[seq][0])\n",
    "    SEQ.append(seq)\n",
    "\n",
    "print('calulating HC probes')\n",
    "\n",
    "threads = 32 # number of cores to run calulaiton on\n",
    "pool = ThreadPool(threads)\n",
    "results = pool.starmap(hamming_close_FP, zip(SEQ,FP_num),20)      \n",
    "pool.close() \n",
    "pool.join()\n",
    "\n",
    "for result in results:\n",
    "    for key, value in zip(result[0],result[1]):\n",
    "        probe_Look_up[key] = value \n",
    "                \n",
    "    \n",
    "# =============================================================================\n",
    "\n",
    "#for round 1 and 2 barcodes\n",
    "BClookUPpath = 'Path/to/CSV' #formated CSV with columns named: 'Well Position', 'Name'\n",
    "# with the 'Well Position' being the well of a 96welll plat and 'Name' being the DNA sequence of the barcode\n",
    "\n",
    "\n",
    "#for round 3 barcodes\n",
    "BClookUPpath3 = 'Path/to/CSV' #formated CSV with columns named: 'Well Position', 'Name'\n",
    "# with the 'Well Position' being the well of a 96welll plat and 'Name' being the DNA sequence of the barcode\n",
    "\n",
    "lookupDF = pd.read_csv(BClookUPpath)\n",
    "lookupDF3 = pd.read_csv(BClookUPpath3)\n",
    "BC_lookupR3pre = {}\n",
    "BC_lookupR3_1 = {}\n",
    "\n",
    "for well, seq in zip(lookupDF3['Well Position'].tolist(),lookupDF3['Name'].tolist()):\n",
    "        seq = reverse_complement(seq)\n",
    "        BC_lookupR3_1[seq] = well \n",
    "        for HC in hamming_close(seq,distance = 2):\n",
    "            if BC_lookupR3pre.get(HC) == None: \n",
    "                BC_lookupR3pre[HC] = []\n",
    "            BC_lookupR3pre[HC].append(well)\n",
    "     \n",
    "BC_lookupR3 = {}\n",
    "\n",
    "# remove ambigious BCs\n",
    "for seq in BC_lookupR3pre:\n",
    "    if len(set(BC_lookupR3pre[seq])) == 1:\n",
    "        BC_lookupR3[seq] = BC_lookupR3pre[seq][0]   \n",
    "\n",
    "\n",
    "for well, seq in zip(lookupDF['Well Position'].tolist(),lookupDF['Name'].tolist()):\n",
    "    BC_lookupR1_R2_1[seq] = well \n",
    "    for HC in hamming_close(seq,distance = 2):\n",
    "        if BC_lookupR1_R2pre.get(HC) == None: \n",
    "            BC_lookupR1_R2pre[HC] = []\n",
    "        BC_lookupR1_R2pre[HC].append(well)\n",
    "     \n",
    "BC_lookupR1_R2 = {}\n",
    "\n",
    "# remove ambigious BCs\n",
    "for seq in BC_lookupR1_R2pre:\n",
    "    if len(set(BC_lookupR1_R2pre[seq])) == 1:\n",
    "        BC_lookupR1_R2[seq] = BC_lookupR1_R2pre[seq][0]\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     27,
     57,
     67,
     86,
     346,
     368
    ]
   },
   "outputs": [],
   "source": [
    "# analysis of sequences for hybriseq\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def getKmer(seq, k):\n",
    "    \n",
    "    ''' get all subsequences from seq of length k return list \n",
    "    \n",
    "        getKmer(seq, k)\n",
    "            seq: str \n",
    "            k: int subseq to lenth to find\n",
    "    '''\n",
    "    \n",
    "    if k>len(seq):\n",
    "         return([])\n",
    "    # catch case len seq = k\n",
    "    if len(seq)==k:\n",
    "        return([seq])\n",
    "    kmer = []\n",
    "    for i in range(len(seq)-k):\n",
    "        kmer.append(seq[i:i+k])\n",
    "    return(kmer)\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# look for BC, exact first then close, args: close, exact \n",
    "def lookUPalg(BC_lookup,\n",
    "              BC_lookup_1,\n",
    "              seq_line,\n",
    "              start = -9,\n",
    "              stop = 0,\n",
    "              k = 7):\n",
    "  \n",
    "    kmer = getKmer(seq_line[start:stop], k = k)\n",
    "    exact = []\n",
    "    exactP = []\n",
    "    close = []\n",
    "    closeP = []\n",
    "    for sub in kmer:\n",
    "        if BC_lookup_1.get(sub)!= None:\n",
    "            exact.append(BC_lookup_1.get(sub))\n",
    "            \n",
    "            exactP.append(seq_line.find(sub,start,stop))\n",
    "    if len(exact) != 0:\n",
    "        return(exact,close,exactP,closeP)\n",
    "    \n",
    "    else:\n",
    "        for sub in kmer:\n",
    "            if BC_lookup.get(sub)!= None:\n",
    "                close.append(BC_lookup.get(sub))\n",
    "                closeP.append(seq_line.find(sub,start,stop))\n",
    "    if len(close) != 0:\n",
    "        return(exact,close,exactP,closeP)\n",
    "    return(None)\n",
    "\n",
    "# lookuptable is intager not DNA\n",
    "def probe_LU_slide2(subseq, lookuptable,simdistance =30):\n",
    "    Fp_inSeq = []\n",
    "    for sub in [DNA2int(DNA, N = 'A') for DNA in getKmer(subseq,simdistance)]:\n",
    "        if lookuptable.get(sub)!= None:\n",
    "            Fp_inSeq.append(lookuptable[sub])    \n",
    "    if len(set(Fp_inSeq)) >= 1:\n",
    "        return(Fp_inSeq[0],subseq)\n",
    "    else:\n",
    "        return('none', 'none')\n",
    "\n",
    "def read_DFs(RAWreadDF, # dataframe with raw reads \n",
    "             BC_lookupR3, #look up dict for barcode sequences round 1&2 hamming = 1\n",
    "             BC_lookupR3_1,# look up dict for barcode sequences round 3 hamming = 0 \n",
    "             BC_lookupR1_R2, # look up dict for barcode sequences round 1&2 hamming = 1 \n",
    "             BC_lookupR1_R2_1, # look up dict for barcode sequences round 1&2 hamming = 0\n",
    "             probe_Look_up,# look up dict for probe sequences hamming = 2\n",
    "             simdistance = 30, # probe length\n",
    "             threads = 16):  # number of cores to run analysis on \n",
    "    \n",
    "    '''\n",
    "        read raw reads datafram and return datafram with sequence info\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    t0  = time.time()\n",
    "    total_reads = 0\n",
    "        \n",
    "    # extract sequence info\n",
    "    def  read_seq_line(line,\n",
    "                       line2,\n",
    "                       BC_lookupR3,\n",
    "                       BC_lookupR3_1,\n",
    "                       BC_lookupR1_R2,\n",
    "                       BC_lookupR1_R2_1,\n",
    "                       probe_Look_up,\n",
    "                       simdistance):\n",
    "\n",
    "        seq_line = line\n",
    "        seq_line2 = line2\n",
    "\n",
    "        seq_line = reverse_complement(seq_line)\n",
    "        \n",
    "        all_reads1 = seq_line\n",
    "        all_reads2 = seq_line2\n",
    "    \n",
    "        #read 1 stuff\n",
    "        R3 = 0\n",
    "        R2 = 0\n",
    "        R1 = 0\n",
    "        \n",
    "        ## check for specfic regions in R1, R2, R3 \n",
    "        R1_offset = 0\n",
    "        R2_offset = 35\n",
    "        R3_offset = 57\n",
    "        \n",
    "        R1_start = seq_line[R1_offset:25].find('ATTCG')\n",
    "        R2_start = seq_line[R2_offset:56].find('TGCTTGAG')\n",
    "        R3_start = seq_line[R3_offset:].find('GTTTCG')\n",
    "\n",
    "        # check if all regions are there\n",
    "        if R3_start != -1:\n",
    "            R3 = 1 \n",
    "        if R2_start != -1:\n",
    "            R2 = 1       \n",
    "        if R1_start != -1:\n",
    "            R1 = 1\n",
    "        total = R3 + R2 + R1 \n",
    "        if total != 3:\n",
    "            fa = []\n",
    "            if R3_start == -1:\n",
    "                fa.append('R3')\n",
    "            if R2_start == -1:\n",
    "                fa.append('R2')\n",
    "            if R1_start == -1:\n",
    "                fa.append('R1')\n",
    "            Fail = ''.join(fa)\n",
    "        else:\n",
    "            Fail = 'good'\n",
    "                            \n",
    "        #if True:\n",
    "        #R1\n",
    "        R1_seq = None\n",
    "        if R1_start != -1:\n",
    "            R1_s = R1_offset+R1_start+len('ATTCG')\n",
    "    \n",
    "            R1_seq = lookUPalg(BC_lookupR1_R2,\n",
    "                        BC_lookupR1_R2_1,\n",
    "                        seq_line = seq_line,\n",
    "                        start = R1_s,\n",
    "                        stop = R1_s + 7 + 2,\n",
    "                        k = 7)\n",
    "        \n",
    "        #R2\n",
    "        R2_seq = None\n",
    "\n",
    "        if R2_start != -1:\n",
    "            R2_s = R2_offset+R2_start+len('TGCTTGA')\n",
    "\n",
    "            R2_seq = lookUPalg(BC_lookupR1_R2,\n",
    "                        BC_lookupR1_R2_1,\n",
    "                        seq_line = seq_line,\n",
    "                        start = R2_s,\n",
    "                        stop = R2_s + 7 + 2,\n",
    "                        k = 7)\n",
    "                \n",
    "        #R3 \n",
    "        R3_seq = None\n",
    "        seq_line_len = len(seq_line)\n",
    "        \n",
    "        if R3_start != -1:\n",
    "            R3_s =  R3_offset + R3_start+ len('GTTTCG')\n",
    "            R3_seq = lookUPalg(BC_lookupR3,\n",
    "                               BC_lookupR3_1,\n",
    "                               seq_line = seq_line,\n",
    "                               start = R3_s,\n",
    "                               stop = R3_s+7,\n",
    "                               k = 7)  \n",
    "        \n",
    "        #R1\n",
    "        if R1_seq == None:\n",
    "            R1_seq = 'none'\n",
    "            BC1p = 'none'\n",
    "        else:\n",
    "            exact = R1_seq[0]\n",
    "            colose = R1_seq[1]\n",
    "            exactp = R1_seq[2]\n",
    "            colosep = R1_seq[3]\n",
    "            \n",
    "            #check for ambugious identification \n",
    "            if len(exact) == 1:\n",
    "                R1_seq = exact[0]\n",
    "                BC1p = exactp[0]\n",
    "            elif len(colose) == 1:\n",
    "                R1_seq = colose[0]\n",
    "                BC1p = colosep[0]\n",
    "            else:\n",
    "                R1_seq = 'none'    \n",
    "                BC1p = 'none'\n",
    "        \n",
    "        #R2\n",
    "        if R2_seq == None:\n",
    "            R2_seq = 'none'\n",
    "            BC2p = 'none'\n",
    "        else:\n",
    "            exact = R2_seq[0]\n",
    "            colose = R2_seq[1]\n",
    "            exactp = R2_seq[2]\n",
    "            colosep = R2_seq[3]\n",
    "            \n",
    "            #check for ambugious identification \n",
    "            if len(exact) == 1:\n",
    "                R2_seq = exact[0]\n",
    "                BC2p = exactp[0]\n",
    "            elif len(colose) == 1:\n",
    "                R2_seq = colose[0]\n",
    "                BC2p = colosep[0]\n",
    "            else:\n",
    "                R2_seq = 'none'    \n",
    "                BC2p = 'none'\n",
    "        \n",
    "        #R3       \n",
    "        if R3_seq == None:\n",
    "            R3_seq = 'none'\n",
    "            BC3p = 'none'\n",
    "        else:\n",
    "            exact = R3_seq[0]\n",
    "            colose = R3_seq[1]\n",
    "            exactp = R3_seq[2]\n",
    "            colosep = R3_seq[3]\n",
    "            \n",
    "            #check for ambugious identification \n",
    "            if len(exact) == 1:\n",
    "                R3_seq = exact[0]\n",
    "                BC3p = exactp[0]\n",
    "            elif len(colose) == 1:\n",
    "                R3_seq = colose[0]\n",
    "                BC3p = colosep[0]\n",
    "            else:\n",
    "                R3_seq = 'none'    \n",
    "                BC3p = 'none'\n",
    "            \n",
    "        BC1 = R1_seq\n",
    "        BC2 = R2_seq\n",
    "        BC3 = R3_seq\n",
    "    \n",
    "        UMI = seq_line2[60:68]\n",
    "\n",
    "        found = 'none'\n",
    "\n",
    "        ID_R, rseq = probe_LU_slide2(subseq = seq_line2[:30],\n",
    "                                     lookuptable = probe_Look_up,\n",
    "                                     simdistance = simdistance)\n",
    "        \n",
    "        ID_L, lseq = probe_LU_slide2(subseq = seq_line2[30:60],\n",
    "                                     lookuptable = probe_Look_up,\n",
    "                                     simdistance = simdistance)\n",
    "                    \n",
    "        LeftID = ID_L\n",
    "        if lseq == 'none':\n",
    "            LeftSeq = 'none'\n",
    "            Left_probe_num = 'none'\n",
    "        else:\n",
    "            LeftSeq = lseq\n",
    "            Left_probe_num = ID_L\n",
    "        \n",
    "        RightID = ID_R\n",
    "        if rseq == 'none':\n",
    "            RightSeq = 'none'\n",
    "            Right_probe_num = 'none'\n",
    "        else:\n",
    "            RightSeq = rseq\n",
    "            Right_probe_num = ID_R\n",
    "            \n",
    "        return(all_reads1,\n",
    "               all_reads2,\n",
    "               Fail,\n",
    "               BC1,\n",
    "               BC2,\n",
    "               BC3,\n",
    "               BC1p,\n",
    "               BC2p,\n",
    "               BC3p,\n",
    "               UMI,\n",
    "               LeftID,\n",
    "               RightID,\n",
    "               LeftSeq,\n",
    "               RightSeq,\n",
    "               Left_probe_num,\n",
    "               Right_probe_num)\n",
    "                \n",
    "    # run calulations on mulitiple cores \n",
    "    file_num = len(RAWreadDF['R1'])\n",
    "\n",
    "    # set up threads \n",
    "    if threads == -1: \n",
    "        threads = multiprocessing.cpu_count()\n",
    "    pool = ThreadPool(threads)\n",
    "    \n",
    "    print('runing multi, CPU = '+str(threads))\n",
    "    \n",
    "    \n",
    "    results = pool.starmap(read_seq_line, zip(RAWreadDF['R1'],\n",
    "                                              RAWreadDF['R2'],\n",
    "                                              [BC_lookupR3 for x in range(file_num)],\n",
    "                                              [BC_lookupR3_1 for x in range(file_num)],\n",
    "                                              [BC_lookupR1_R2 for x in range(file_num)],\n",
    "                                              [BC_lookupR1_R2_1 for x in range(file_num)],\n",
    "                                              [probe_Look_up for x in range(file_num)],\n",
    "                                              [simdistance for x in range(file_num)]),\n",
    "                                              20)      \n",
    "    pool.close() \n",
    "    pool.join()\n",
    "    \n",
    "    all_reads1_ = [line[0] for line in results]\n",
    "    all_reads2_ = [line[1] for line in results]\n",
    "    Fail_ = [line[2] for line in results]\n",
    "    BC1_ = [line[3] for line in results]\n",
    "    BC2_ = [line[4] for line in results]\n",
    "    BC3_ = [line[5] for line in results]\n",
    "    BC1p_ = [line[6] for line in results]\n",
    "    BC2p_ = [line[7] for line in results]\n",
    "    BC3p_ = [line[8] for line in results]\n",
    "\n",
    "    UMI_ = [line[9] for line in results]\n",
    "    LeftID_ = [line[10] for line in results]\n",
    "    RightID_ = [line[11] for line in results]\n",
    "    LeftSeq_ = [line[12] for line in results]\n",
    "    RightSeq_ = [line[13] for line in results]\n",
    "    Left_probe_num_ = [line[14] for line in results]\n",
    "    Right_probe_num_ = [line[15] for line in results]\n",
    "          \n",
    "    read_data = {'all_reads1':all_reads1_ ,\n",
    "                 'all_reads2':all_reads2_ ,\n",
    "                 'Fail':Fail_,\n",
    "                 'BC1':BC1_,\n",
    "                 'BC2':BC2_,\n",
    "                 'BC3':BC3_,\n",
    "                 'BC1p':BC1p_,\n",
    "                 'BC2p':BC2p_,\n",
    "                 'BC3p':BC3p_,\n",
    "                 'UMI':UMI_,\n",
    "                 'LeftID':LeftID_,\n",
    "                 'RightID':RightID_,\n",
    "                 'LeftSeq':LeftSeq_, \n",
    "                 'RightSeq':RightSeq_,\n",
    "                 'Left_num':Left_probe_num_,\n",
    "                 'Right_num':Right_probe_num_}\n",
    "\n",
    "    read_col = ['all_reads1' ,\n",
    "             'all_reads2' ,\n",
    "             'Fail',\n",
    "             'BC1',\n",
    "             'BC2',\n",
    "             'BC3',\n",
    "             'BC1p',\n",
    "             'BC2p',\n",
    "             'BC3p',\n",
    "             'UMI',\n",
    "             'LeftID',\n",
    "             'RightID',\n",
    "             'LeftSeq',\n",
    "             'RightSeq',\n",
    "             'Left_num',\n",
    "             'Right_num']\n",
    "    \n",
    "    readDF = pd.DataFrame(data = read_data, columns = read_col)\n",
    "    # return dataframe with reads and regions detected for probe, R1,R2,R3, UMI\n",
    "    return(readDF)\n",
    "\n",
    "# filter for valid reads \n",
    "def good_reads(readDF):\n",
    "    '''\n",
    "        filter datafram for good reads \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    readDF['LeqR'] = [L==R for L,R in zip(readDF['Left_num'],readDF['Right_num'])]\n",
    "    readDF1 = readDF[readDF['LeqR']==True] # ensure same probes for both left and right \n",
    "    readDF1 = readDF1[readDF1['Fail']=='good'] # ensure sequence has universal reagions in R1,R2,R3\n",
    "    readDF1 = readDF1[readDF1['BC1']!='none'] # ensure has barcode 1\n",
    "    readDF1 = readDF1[readDF1['BC2']!='none'] # ensure has barcode 2\n",
    "    readDF1 = readDF1[readDF1['BC3']!='none'] # ensure has barcode 3\n",
    "    readDF1 = readDF1[readDF1['LeftID']!='none'] # ensure has left probe\n",
    "    readDF1 = readDF1[readDF1['RightID']!='none'] # ensure has right probe\n",
    "    readDF1['CellID'] = readDF1['BC1']+readDF1['BC2']+readDF1['BC3'] # make cell barcode\n",
    "    readDF1['UMI_CellID'] = readDF1['UMI']+readDF1['CellID']+readDF1['Left_num'] # make composit UMI\n",
    "    readDF1.drop_duplicates(subset='UMI_CellID', keep='first', inplace=True) # drop UMI\n",
    "    return(readDF1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
